!pip install vit-keras
# Visual transformer strictly works with 224 image size
# Define function to resize images within the pipeline
def resize_images(image, label, new_size=(224, 224)):
    image = tf.image.resize(image, new_size)  # Resize each image
    return image, label

train_images_2 = (
    tf.data.Dataset.from_tensor_slices((X_train, y_train_integar))
    .map(lambda x, y: resize_images(x, y, new_size=(224, 224)), num_parallel_calls=tf.data.AUTOTUNE)
    .shuffle(buffer_size=len(X_train))  # Shuffle the training set
    .repeat()  # Repeat dataset for multiple epochs
    .batch(batch_size)  # Batch the dataset
    .prefetch(tf.data.AUTOTUNE)  # Optimize performance by prefetching
)

test_images_2 = (
    tf.data.Dataset.from_tensor_slices((X_test, y_test_integar))
    .map(lambda x, y: resize_images(x, y, new_size=(224, 224)), num_parallel_calls=tf.data.AUTOTUNE)
    .batch(batch_size)  # Batch the test set
    .prefetch(tf.data.AUTOTUNE)  # Prefetch for better performance
)

val_images_2 = (
    tf.data.Dataset.from_tensor_slices((X_val, y_val_integar))
    .map(lambda x, y: resize_images(x, y, new_size=(224, 224)), num_parallel_calls=tf.data.AUTOTUNE)
    .batch(batch_size)  # Batch the validation set
    .prefetch(tf.data.AUTOTUNE)  # Prefetch to optimize speed
)
from tensorflow.keras.layers import Input, Flatten, Dense, Dropout
from vit_keras import vit
# Load the pre-built Vision Transformer model - vit_b16
vit_model = vit.vit_b16(
    image_size=224,        # Image size (224x224)
    pretrained=True,       # Use pretrained weights
    include_top=False,     # Exclude the top classification layer
    pretrained_top=False   # Exclude pretrained top layer
)

# Freeze the layers of the pre-trained ViT model
for layer in vit_model.layers:
    layer.trainable = False

# Create a Sequential model and add layers
model_vit_b16 = Sequential()
model_vit_b16.add(Input(shape=(224, 224, 3)))  # Input layer with the correct input shape
model_vit_b16.add(vit_model)
model_vit_b16.add(Flatten())  # Flatten the output for dense layers

# Adding custom fully connected layers
model_vit_b16.add(Dense(64, activation='relu'))
model_vit_b16.add(Dropout(0.2))
model_vit_b16.add(Dense(32, activation='relu'))
model_vit_b16.add(Dense(9, activation='softmax'))
# Define optimizer and compile the model
opt = Adam(learning_rate=1e-3)
model_vit_b16.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Print the model summary
model_vit_b16.summary()
# Training the ViT model

model_vit_b16_history = model_vit_b16.fit(train_images_2, epochs=20, validation_data= val_images_2,
                                  batch_size=32, steps_per_epoch=len(X_train)//batch_size, verbose =1)
# Save the entire model
from tensorflow.keras.models import load_model

model_path = "/content/drive/MyDrive/model_vit_b16.keras"

model_vit_b16.save(model_path)
import pickle

# Save the training history
history_path = "/content/drive/MyDrive/model_vit_b16_history.pkl"
with open(history_path, 'wb') as file_pi:
    pickle.dump(model_vit_b16_history.history, file_pi)
model_vit_b16 = load_model(model_path, safe_mode=False)
# evaluate cnn model's accuracy and loss across eopochs
plot_accuracy_loss_chart(model_vit_b16_history, 'Visual Transformer Model')
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score, precision_score, recall_score, f1_score

y_pred_probs = model_vit_b16.predict(test_images_2)
y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels

# Extract the true labels from the test dataset
y_true = np.concatenate([y for x, y in test_images_2], axis=0)  # Collect true labels from the dataset

# Compute the confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Display the confusion matrix with class names
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_names.values()))

# Plot the confusion matrix with rotated x-axis labels
fig, ax = plt.subplots(figsize=(10, 10))
disp.plot(ax=ax, cmap=plt.cm.Blues)
plt.xticks(rotation=45, ha='right')  # Rotate class names on x-axis to avoid overlap
plt.title('Confusion Matrix')
plt.show()

# Compute and display additional metrics
print("Accuracy:", accuracy_score(y_true, y_pred))
print("Precision (macro):", precision_score(y_true, y_pred, average='macro'))
print("Recall (macro):", recall_score(y_true, y_pred, average='macro'))
print("F1 Score (macro):", f1_score(y_true, y_pred, average='macro'))

# Detailed classification report
print("\nClassification Report:\n")
print(classification_report(y_true, y_pred, target_names=list(class_names.values())))

